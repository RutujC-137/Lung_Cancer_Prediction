{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27cc9525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "912a0a27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Schema:\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- diagnosis_date: timestamp (nullable = true)\n",
      " |-- cancer_stage: string (nullable = true)\n",
      " |-- family_history: string (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- cholesterol_level: integer (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- asthma: integer (nullable = true)\n",
      " |-- cirrhosis: integer (nullable = true)\n",
      " |-- other_cancer: integer (nullable = true)\n",
      " |-- treatment_type: string (nullable = true)\n",
      " |-- end_treatment_date: timestamp (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      "\n",
      "First 5 rows of original data:\n",
      "+---+----+------+-----------+-------------------+------------+--------------+--------------+----+-----------------+------------+------+---------+------------+--------------+-------------------+--------+\n",
      "| id| age|gender|    country|     diagnosis_date|cancer_stage|family_history|smoking_status| bmi|cholesterol_level|hypertension|asthma|cirrhosis|other_cancer|treatment_type| end_treatment_date|survived|\n",
      "+---+----+------+-----------+-------------------+------------+--------------+--------------+----+-----------------+------------+------+---------+------------+--------------+-------------------+--------+\n",
      "|  1|64.0|  Male|     Sweden|2016-04-05 00:00:00|     Stage I|           Yes|Passive Smoker|29.4|              199|           0|     0|        1|           0|  Chemotherapy|2017-09-10 00:00:00|       0|\n",
      "|  2|50.0|Female|Netherlands|2023-04-20 00:00:00|   Stage III|           Yes|Passive Smoker|41.2|              280|           1|     1|        0|           0|       Surgery|2024-06-17 00:00:00|       1|\n",
      "|  3|65.0|Female|    Hungary|2023-04-05 00:00:00|   Stage III|           Yes| Former Smoker|44.0|              268|           1|     1|        0|           0|      Combined|2024-04-09 00:00:00|       0|\n",
      "|  4|51.0|Female|    Belgium|2016-02-05 00:00:00|     Stage I|            No|Passive Smoker|43.0|              241|           1|     1|        0|           0|  Chemotherapy|2017-04-23 00:00:00|       0|\n",
      "|  5|37.0|  Male| Luxembourg|2023-11-29 00:00:00|     Stage I|            No|Passive Smoker|19.7|              178|           0|     0|        0|           0|      Combined|2025-01-08 00:00:00|       0|\n",
      "+---+----+------+-----------+-------------------+------------+--------------+--------------+----+-----------------+------------+------+---------+------------+--------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total rows before preprocessing: 890000\n",
      "\n",
      "Numerical Columns: ['age', 'bmi', 'cholesterol_level', 'hypertension', 'asthma', 'cirrhosis', 'other_cancer']\n",
      "Categorical Columns: ['gender', 'country', 'cancer_stage', 'family_history', 'smoking_status', 'treatment_type']\n",
      "Date Columns (excluded from this preprocessing for CSV output): ['diagnosis_date', 'end_treatment_date']\n",
      "\n",
      "Total rows after handling missing values (imputed/filled): 890000\n",
      "\n",
      "Schema of data to be saved to CSV:\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- age: double (nullable = false)\n",
      " |-- bmi: double (nullable = false)\n",
      " |-- cholesterol_level: double (nullable = false)\n",
      " |-- hypertension: double (nullable = false)\n",
      " |-- asthma: double (nullable = false)\n",
      " |-- cirrhosis: double (nullable = false)\n",
      " |-- other_cancer: double (nullable = false)\n",
      " |-- gender_indexed: double (nullable = false)\n",
      " |-- country_indexed: double (nullable = false)\n",
      " |-- cancer_stage_indexed: double (nullable = false)\n",
      " |-- family_history_indexed: double (nullable = false)\n",
      " |-- smoking_status_indexed: double (nullable = false)\n",
      " |-- treatment_type_indexed: double (nullable = false)\n",
      " |-- survived: integer (nullable = true)\n",
      "\n",
      "First 5 rows of data to be saved to CSV (with indexed categories):\n",
      "+---+----+----+-----------------+------------+------+---------+------------+--------------+---------------+--------------------+----------------------+----------------------+----------------------+--------+\n",
      "| id| age| bmi|cholesterol_level|hypertension|asthma|cirrhosis|other_cancer|gender_indexed|country_indexed|cancer_stage_indexed|family_history_indexed|smoking_status_indexed|treatment_type_indexed|survived|\n",
      "+---+----+----+-----------------+------------+------+---------+------------+--------------+---------------+--------------------+----------------------+----------------------+----------------------+--------+\n",
      "|  1|64.0|29.4|            199.0|         0.0|   0.0|      1.0|         0.0|           0.0|            4.0|                 2.0|                   1.0|                   0.0|                   0.0|       0|\n",
      "|  2|50.0|41.2|            280.0|         1.0|   1.0|      0.0|         0.0|           1.0|            8.0|                 0.0|                   1.0|                   0.0|                   1.0|       1|\n",
      "|  3|65.0|44.0|            268.0|         1.0|   1.0|      0.0|         0.0|           1.0|           12.0|                 0.0|                   1.0|                   2.0|                   2.0|       0|\n",
      "|  4|51.0|43.0|            241.0|         1.0|   1.0|      0.0|         0.0|           1.0|           11.0|                 2.0|                   0.0|                   0.0|                   0.0|       0|\n",
      "|  5|37.0|19.7|            178.0|         0.0|   0.0|      0.0|         0.0|           0.0|           23.0|                 2.0|                   0.0|                   0.0|                   2.0|       0|\n",
      "+---+----+----+-----------------+------------+------+---------+------------+--------------+---------------+--------------------+----------------------+----------------------+----------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Processed data saved to: file:///home/talentum/spark_data/preprocessed_lung_cancer_output\n",
      "You will find the actual CSV file (e.g., part-00000-....csv) inside the '/home/talentum/spark_data/preprocessed_lung_cancer_output' directory.\n",
      "You will need to manually copy this file from your VM's home directory to your shared folder if you want to access it from Windows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "# --- Environment Setup (Crucial for Jupyter/PySpark) ---\n",
    "# Set SPARK_HOME to your Spark installation directory.\n",
    "# Based on your previous output, it is /home/talentum/spark.\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "\n",
    "# Set Python executable for PySpark\n",
    "# Using 'python3' as confirmed by sys.executable output.\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python3\"\n",
    "\n",
    "# Add PySpark and Py4J to the Python path\n",
    "# These lines help Python find the necessary PySpark libraries if not configured globally.\n",
    "spark_python_path = os.path.join(os.environ[\"SPARK_HOME\"], \"python\")\n",
    "pyspark_zip_path = os.path.join(spark_python_path, \"lib\", \"pyspark.zip\")\n",
    "\n",
    "# Dynamically find the py4j zip file (its version number changes)\n",
    "py4j_zip_files = glob.glob(os.path.join(spark_python_path, \"lib\", \"py4j-*.zip\"))\n",
    "py4j_zip_path = py4j_zip_files[0] if py4j_zip_files else None\n",
    "\n",
    "if pyspark_zip_path not in sys.path:\n",
    "    sys.path.insert(0, pyspark_zip_path)\n",
    "if py4j_zip_path and py4j_zip_path not in sys.path:\n",
    "    sys.path.insert(0, py4j_zip_path)\n",
    "\n",
    "# --- End of Environment Setup ---\n",
    "\n",
    "\n",
    "# Import necessary PySpark modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Initialize SparkSession\n",
    "# .master(\"local[*]\") tells Spark to run on your local machine using all CPU cores.\n",
    "# .config(\"spark.hadoop.fs.defaultFS\", \"file:///\") explicitly tells Spark to use the local filesystem.\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LungCancerPreprocessing\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"file:///\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset using its absolute path with 'file:///' prefix.\n",
    "# *** UPDATED PATH TO A NON-SHARED LOCATION FOR RELIABILITY ***\n",
    "csv_file_path = \"file:///home/talentum/spark_data/Lung_Cancer.csv\"\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# --- Preprocessing Steps ---\n",
    "\n",
    "# 1. Inspect the schema and some data\n",
    "print(\"Original Schema:\")\n",
    "df.printSchema()\n",
    "print(\"First 5 rows of original data:\")\n",
    "df.show(5)\n",
    "print(f\"Total rows before preprocessing: {df.count()}\")\n",
    "\n",
    "# 2. Identify Numerical, Categorical, Date and Target Columns\n",
    "numerical_cols = ['age', 'bmi', 'cholesterol_level', 'hypertension', 'asthma', 'cirrhosis', 'other_cancer']\n",
    "categorical_cols = ['gender', 'country', 'cancer_stage', 'family_history', 'smoking_status', 'treatment_type']\n",
    "date_cols = ['diagnosis_date', 'end_treatment_date']\n",
    "target_col = 'survived'\n",
    "id_col = 'id'\n",
    "\n",
    "# Ensure all identified columns actually exist in the DataFrame\n",
    "existing_columns = df.columns\n",
    "numerical_cols = [c for c in numerical_cols if c in existing_columns]\n",
    "categorical_cols = [c for c in categorical_cols if c in existing_columns]\n",
    "date_cols = [c for c in date_cols if c in existing_columns]\n",
    "if id_col not in existing_columns:\n",
    "    id_col = None\n",
    "\n",
    "print(f\"\\nNumerical Columns: {numerical_cols}\")\n",
    "print(f\"Categorical Columns: {categorical_cols}\")\n",
    "print(f\"Date Columns (excluded from this preprocessing for CSV output): {date_cols}\")\n",
    "\n",
    "df_processed = df\n",
    "\n",
    "# 3. Handle Missing Values\n",
    "for col_name in numerical_cols:\n",
    "    df_processed = df_processed.withColumn(col_name, col(col_name).cast(DoubleType()))\n",
    "    mean_val = df_processed.agg({col_name: \"avg\"}).collect()[0][0]\n",
    "    if mean_val is not None:\n",
    "        df_processed = df_processed.fillna(mean_val, subset=[col_name])\n",
    "\n",
    "for col_name in categorical_cols:\n",
    "    df_processed = df_processed.fillna('Unknown', subset=[col_name])\n",
    "\n",
    "print(f\"\\nTotal rows after handling missing values (imputed/filled): {df_processed.count()}\")\n",
    "\n",
    "\n",
    "# 4. Feature Engineering / Encoding Categorical Variables\n",
    "indexers_for_csv = [\n",
    "    StringIndexer(inputCol=column, outputCol=column + \"_indexed\", handleInvalid=\"keep\")\n",
    "    for column in categorical_cols\n",
    "]\n",
    "\n",
    "pipeline_for_csv_indexed = Pipeline(stages=indexers_for_csv)\n",
    "pipeline_model_for_csv_indexed = pipeline_for_csv_indexed.fit(df_processed)\n",
    "df_indexed = pipeline_model_for_csv_indexed.transform(df_processed)\n",
    "\n",
    "# 5. Select columns for the final CSV output\n",
    "final_csv_columns_indexed = []\n",
    "if id_col:\n",
    "    final_csv_columns_indexed.append(id_col)\n",
    "final_csv_columns_indexed.extend(numerical_cols)\n",
    "final_csv_columns_indexed.extend([c + \"_indexed\" for c in categorical_cols])\n",
    "if target_col in existing_columns:\n",
    "    final_csv_columns_indexed.append(target_col)\n",
    "\n",
    "final_df_for_csv = df_indexed.select(*final_csv_columns_indexed)\n",
    "\n",
    "\n",
    "print(\"\\nSchema of data to be saved to CSV:\")\n",
    "final_df_for_csv.printSchema()\n",
    "print(\"First 5 rows of data to be saved to CSV (with indexed categories):\")\n",
    "final_df_for_csv.show(5)\n",
    "\n",
    "# Define the output path to a non-shared directory in your home folder\n",
    "# *** UPDATED OUTPUT PATH TO A NON-SHARED LOCATION FOR RELIABILITY ***\n",
    "output_dir_local = \"/home/talentum/spark_data/preprocessed_lung_cancer_output\" # New sub-directory name for clarity\n",
    "output_path_vm_absolute = \"file://\" + output_dir_local # Build file:// path\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir_local, exist_ok=True)\n",
    "\n",
    "# Save the processed data as a single CSV file\n",
    "final_df_for_csv.coalesce(1).write.csv(output_path_vm_absolute, header=True, mode=\"overwrite\")\n",
    "\n",
    "# Stop SparkSession\n",
    "spark.stop()\n",
    "\n",
    "print(f\"\\nProcessed data saved to: {output_path_vm_absolute}\")\n",
    "print(f\"You will find the actual CSV file (e.g., part-00000-....csv) inside the '{output_dir_local}' directory.\")\n",
    "print(\"You will need to manually copy this file from your VM's home directory to your shared folder if you want to access it from Windows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e21679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46201af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8de1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
